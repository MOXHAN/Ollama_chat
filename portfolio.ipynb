{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction**\n",
    "\n",
    "**IMPORTANT:** Installation guide can be found in the readme.md\n",
    "\n",
    "This project aims to leverage existing personal notes of various topics using Large Language Models (LLMs). The notes are available in markdown format and therefore easily readable for both machines and humans in raw format. However, the main usage of said notes in this projects scenario is through the note-taking app Obsidian (https://obsidian.md).\n",
    "\n",
    "## **Obsidian and Open-Source**\n",
    "\n",
    "Obsidian shines through its transparancy in comparison to other apps like Notion. By using the markdown format, taken notes are independent of the Obsidian app and can be just as well read in a simple editor. To support this ideology, which fits very well into the Open-Source idea, I aim to use (Open-Source) non-proprietary LLMS, like Llama, to \"chat\" with my notes. This will allow me better access to ther knowledge I have saved in my notes and furthermore expand it by the knowledge of the LLM, if necessary.\n",
    "\n",
    "## **RAG Workflow**\n",
    "\n",
    "Obsidian saves all markdown files in one folder, which of course can have a more complex sub-structure. This folder is called the \"vault\". To give a LLM access to my vault, I will create contexttual embeddings of the note files. Contextual embeddings are created using an embedding model and do not only convert single words into a numerical representation (vectors), but also capture the context they appear in. The vectors then will be stored in a persistent database, which allows the LLM acces to it. Everytime I will send a Prompt to the LLM, it will compare the prompts context to all my notes and retrieve useful information for the answer, if available.\n",
    " \n",
    "---\n",
    "\n",
    "## **Challenges**\n",
    "\n",
    "### **1. The perfect prompt**\n",
    "\n",
    "A major challenge is the prompt engineering, which describes writing the best prompt to get the best possible answer. To do that I first create a list of requirements for the LLMS answer:\n",
    "1. I only want it to use my notes, if it actually fits the question and is useful and otherwise fall back to its own general knowledge\n",
    "2. I want the LLM to tell me what source it used (my notes or its own knowledge)\n",
    "\n",
    "To find a prompt that leads the LLM to answer both points, I used ChatGPT 4o as help and came up with the following prompt: \"Answer the following question based on the provided notes, if relevant and available, otherwise use your own knowledge to provide an accurate response. After answering, indicate the source by specifying either 'from notes' or 'from general knowledge'. Hereâ€™s the question:\"\n",
    "\n",
    "### **2. Evaluation**\n",
    "\n",
    "To evaluate a LLM is a difficult task, as there are no simple metrics like accuracy. Thus I will evaluate the entire RAG-workflow, so the LLM + embedding model, especially for my use case, meaning how useful is it really. To do this in the best possible way, I came up with the following questions I will evaluate the workflow on:\n",
    "\n",
    "1. To what extend of completeness has the actually matching content available in the notes been used in the response?\n",
    "2. How good/effective has the available content been used for the response?\n",
    "3. Were all points mentioned in the prompt attended? (sub-questions, asked to provide source, include example names etc.)\n",
    "4. Extend of Hallucination and/or using wrong/not aimed for information (For the purpose of calculating a total score at the end, this score is in the range of -10 to 0 with -10 = much hallucination, 0 = no hallucination)\n",
    "\n",
    "Each question will be evaluated on a scale from 0 to 10, where 0 is the worst and 10 the best possible outcome.\n",
    "\n",
    "## **LLMs and Embedding-Models Choice**\n",
    "\n",
    "I tested the following LLMs:\n",
    "\n",
    "1. **Llama 3 8B**\n",
    "2. **Llama 3.2 1B**\n",
    "3. **gemma2 2B**\n",
    "4. **phi 3.5 3.8B**\n",
    "\n",
    "And I will use the embedding model **nomic-embed-text**.\n",
    "\n",
    "---\n",
    "\n",
    "## **The Application**\n",
    "\n",
    "The actual application presenting a chat-interface to communicate with the LLM is a Streamlit GUI. A Dockerfile ready to build is included in this repo. Simply use the command docker build and start the container.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testing**\n",
    "\n",
    "In this repo are 3 different note files in markdown format, which are copies from my original vault. I will ask every model 3 questions about each note and evaluate it on the questions I listed before. The results can be found in the results.xlsx and are presented below. Each answer is zero-shot, meaning I ask each question only once and evaluate the answer.\n",
    "\n",
    "For each note, I will simply ask the model what it can tell me about the topic mentioned in the title of the note, based on my notes. For example, if the note is called \"RAG Workflows\", I will ask the model to tell me about RAG workflows, based on my notes. The second and third question will be a follow-up, which is topic-specific. The questions and answers are included in the results file.\n",
    "\n",
    "**REMARK**\n",
    "\n",
    "The rest of my notes are not included in this repo. Sometimes \"wrong\" notes or not the notes I intended the LLM to use were retrieved by the RAG-workflow, which therefore lead to mistakes that arent reproducible with this repo.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Results**\n",
    "\n",
    "First, I will present the achieved scores by each model and present an overall winner and a winner per topic/note. After that, I will present my overall observations about the answers and styles of the LLMs.\n",
    "\n",
    "## **I. Scoring**\n",
    "\n",
    "First, I simply load the results, including all questions, answers and the models scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note</th>\n",
       "      <th>question</th>\n",
       "      <th>llama3 -answer</th>\n",
       "      <th>llama 3 - score 1</th>\n",
       "      <th>llama 3 - score 2</th>\n",
       "      <th>llama 3 - score 3</th>\n",
       "      <th>llama 3 - score 4</th>\n",
       "      <th>llama 3 - total</th>\n",
       "      <th>llama 3.2 - answer</th>\n",
       "      <th>llama 3.2 - score 1</th>\n",
       "      <th>...</th>\n",
       "      <th>gemma 2 - score 2</th>\n",
       "      <th>gemma 2 - score 3</th>\n",
       "      <th>gemma 2 - score 4</th>\n",
       "      <th>gemma 2 - total</th>\n",
       "      <th>phi 3.5 - answer</th>\n",
       "      <th>phi 3.5 - score 1</th>\n",
       "      <th>phi 3.5 - score 2</th>\n",
       "      <th>phi 3.5 - score 3</th>\n",
       "      <th>phi 3.5 - score 4</th>\n",
       "      <th>phi 3.5 - total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision trees</td>\n",
       "      <td>what can you tell me about decision trees, bas...</td>\n",
       "      <td>Based on your notes, here's what I can summari...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>I can provide an answer based on my general kn...</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>26</td>\n",
       "      <td>Based on the provided notes from a data scienc...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision trees</td>\n",
       "      <td>Explain to me what \"breadth\" means in the cont...</td>\n",
       "      <td>According to your notes, \"Breadth\" refers to t...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>From notes:\\n\\nIn the context of decision tree...</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>In the provided note excerpts regarding decisi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decision trees</td>\n",
       "      <td>What methods to fight overfitting are there in...</td>\n",
       "      <td>What methods to fight overfitting are there in...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>From notes:\\n\\nOverfitting is a common issue w...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>From the provided \"Notes\" on Decision Trees wi...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             note                                           question  \\\n",
       "0  decision trees  what can you tell me about decision trees, bas...   \n",
       "1  decision trees  Explain to me what \"breadth\" means in the cont...   \n",
       "2  decision trees  What methods to fight overfitting are there in...   \n",
       "\n",
       "                                      llama3 -answer  llama 3 - score 1  \\\n",
       "0  Based on your notes, here's what I can summari...                  9   \n",
       "1  According to your notes, \"Breadth\" refers to t...                 10   \n",
       "2  What methods to fight overfitting are there in...                 10   \n",
       "\n",
       "   llama 3 - score 2  llama 3 - score 3  llama 3 - score 4  llama 3 - total  \\\n",
       "0                 10                 10                  0               29   \n",
       "1                  7                 10                  0               27   \n",
       "2                  9                 10                  0               29   \n",
       "\n",
       "                                  llama 3.2 - answer  llama 3.2 - score 1  \\\n",
       "0  I can provide an answer based on my general kn...                    8   \n",
       "1  From notes:\\n\\nIn the context of decision tree...                    7   \n",
       "2  From notes:\\n\\nOverfitting is a common issue w...                    0   \n",
       "\n",
       "   ...  gemma 2 - score 2  gemma 2 - score 3  gemma 2 - score 4  \\\n",
       "0  ...                 10                  8                 -1   \n",
       "1  ...                 10                 10                  0   \n",
       "2  ...                 10                 10                  0   \n",
       "\n",
       "   gemma 2 - total                                   phi 3.5 - answer  \\\n",
       "0               26  Based on the provided notes from a data scienc...   \n",
       "1               30  In the provided note excerpts regarding decisi...   \n",
       "2               30  From the provided \"Notes\" on Decision Trees wi...   \n",
       "\n",
       "   phi 3.5 - score 1  phi 3.5 - score 2  phi 3.5 - score 3  phi 3.5 - score 4  \\\n",
       "0                  9                 10                  8                 -1   \n",
       "1                  0                  0                  0                -10   \n",
       "2                 10                  7                  9                 -1   \n",
       "\n",
       "   phi 3.5 - total  \n",
       "0               26  \n",
       "1              -10  \n",
       "2               25  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_excel('results.xlsx')\n",
    "results.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we are only interested in the scores here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note</th>\n",
       "      <th>question</th>\n",
       "      <th>llama3 -answer</th>\n",
       "      <th>llama 3 - total</th>\n",
       "      <th>llama 3.2 - answer</th>\n",
       "      <th>llama 3.2 - total</th>\n",
       "      <th>gemma 2 - answer</th>\n",
       "      <th>gemma 2 - total</th>\n",
       "      <th>phi 3.5 - answer</th>\n",
       "      <th>phi 3.5 - total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision trees</td>\n",
       "      <td>what can you tell me about decision trees, bas...</td>\n",
       "      <td>Based on your notes, here's what I can summari...</td>\n",
       "      <td>29</td>\n",
       "      <td>I can provide an answer based on my general kn...</td>\n",
       "      <td>20</td>\n",
       "      <td>Based on your notes, here's a breakdown of dec...</td>\n",
       "      <td>26</td>\n",
       "      <td>Based on the provided notes from a data scienc...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision trees</td>\n",
       "      <td>Explain to me what \"breadth\" means in the cont...</td>\n",
       "      <td>According to your notes, \"Breadth\" refers to t...</td>\n",
       "      <td>27</td>\n",
       "      <td>From notes:\\n\\nIn the context of decision tree...</td>\n",
       "      <td>13</td>\n",
       "      <td>In the context of decision trees, \"breadth\" re...</td>\n",
       "      <td>30</td>\n",
       "      <td>In the provided note excerpts regarding decisi...</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decision trees</td>\n",
       "      <td>What methods to fight overfitting are there in...</td>\n",
       "      <td>What methods to fight overfitting are there in...</td>\n",
       "      <td>29</td>\n",
       "      <td>From notes:\\n\\nOverfitting is a common issue w...</td>\n",
       "      <td>-3</td>\n",
       "      <td>Here are a few methods for fighting overfittin...</td>\n",
       "      <td>30</td>\n",
       "      <td>From the provided \"Notes\" on Decision Trees wi...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             note                                           question  \\\n",
       "0  decision trees  what can you tell me about decision trees, bas...   \n",
       "1  decision trees  Explain to me what \"breadth\" means in the cont...   \n",
       "2  decision trees  What methods to fight overfitting are there in...   \n",
       "\n",
       "                                      llama3 -answer  llama 3 - total  \\\n",
       "0  Based on your notes, here's what I can summari...               29   \n",
       "1  According to your notes, \"Breadth\" refers to t...               27   \n",
       "2  What methods to fight overfitting are there in...               29   \n",
       "\n",
       "                                  llama 3.2 - answer  llama 3.2 - total  \\\n",
       "0  I can provide an answer based on my general kn...                 20   \n",
       "1  From notes:\\n\\nIn the context of decision tree...                 13   \n",
       "2  From notes:\\n\\nOverfitting is a common issue w...                 -3   \n",
       "\n",
       "                                    gemma 2 - answer  gemma 2 - total  \\\n",
       "0  Based on your notes, here's a breakdown of dec...               26   \n",
       "1  In the context of decision trees, \"breadth\" re...               30   \n",
       "2  Here are a few methods for fighting overfittin...               30   \n",
       "\n",
       "                                    phi 3.5 - answer  phi 3.5 - total  \n",
       "0  Based on the provided notes from a data scienc...               26  \n",
       "1  In the provided note excerpts regarding decisi...              -10  \n",
       "2  From the provided \"Notes\" on Decision Trees wi...               25  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = results.iloc[:,[0,1,2,7,8,13,14,19,20,25]]\n",
    "scores.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Topic 1 - general**\n",
    "\n",
    "To get a general feeling for the LLM and its style of writing, I ask two simple general questions:\n",
    "\n",
    "1. \"Hi, how are you doing?\"\n",
    "2. \"Who are you?\"\n",
    "\n",
    "Especially the second question is interesting to take a look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note</th>\n",
       "      <th>question</th>\n",
       "      <th>llama3 -answer</th>\n",
       "      <th>llama 3 - total</th>\n",
       "      <th>llama 3.2 - answer</th>\n",
       "      <th>llama 3.2 - total</th>\n",
       "      <th>gemma 2 - answer</th>\n",
       "      <th>gemma 2 - total</th>\n",
       "      <th>phi 3.5 - answer</th>\n",
       "      <th>phi 3.5 - total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>general</td>\n",
       "      <td>Hi, how are you doing?</td>\n",
       "      <td>I'm just an AI, I don't have a physical presen...</td>\n",
       "      <td>30</td>\n",
       "      <td>I'm doing well, thank you for asking.\\n\\nFrom ...</td>\n",
       "      <td>27</td>\n",
       "      <td>Hello! I'm doing well, thank you for asking. ðŸ˜Š...</td>\n",
       "      <td>27</td>\n",
       "      <td>I'm just a language model AI developed by Micr...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>general</td>\n",
       "      <td>Who are you?</td>\n",
       "      <td>I'm just an AI, I don't have a personal identi...</td>\n",
       "      <td>30</td>\n",
       "      <td>I'm not sure from the notes.\\n\\nFrom general k...</td>\n",
       "      <td>-10</td>\n",
       "      <td>I am Gemma, an AI assistant trained to be info...</td>\n",
       "      <td>29</td>\n",
       "      <td>I'm just a language model AI developed by Micr...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       note                question  \\\n",
       "9   general  Hi, how are you doing?   \n",
       "10  general            Who are you?   \n",
       "\n",
       "                                       llama3 -answer  llama 3 - total  \\\n",
       "9   I'm just an AI, I don't have a physical presen...               30   \n",
       "10  I'm just an AI, I don't have a personal identi...               30   \n",
       "\n",
       "                                   llama 3.2 - answer  llama 3.2 - total  \\\n",
       "9   I'm doing well, thank you for asking.\\n\\nFrom ...                 27   \n",
       "10  I'm not sure from the notes.\\n\\nFrom general k...                -10   \n",
       "\n",
       "                                     gemma 2 - answer  gemma 2 - total  \\\n",
       "9   Hello! I'm doing well, thank you for asking. ðŸ˜Š...               27   \n",
       "10  I am Gemma, an AI assistant trained to be info...               29   \n",
       "\n",
       "                                     phi 3.5 - answer  phi 3.5 - total  \n",
       "9   I'm just a language model AI developed by Micr...               29  \n",
       "10  I'm just a language model AI developed by Micr...               28  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general = scores.tail(2)\n",
    "general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3 -answer\n",
      "I'm just an AI, I don't have a personal identity or physical existence. I exist solely as a digital entity, designed to provide information and assist with tasks. My purpose is to help users like you by answering questions and providing relevant information.\n",
      "\n",
      "Source: from general knowledge\n",
      "\n",
      " --- END OF ANSWER ---\n",
      "\n",
      "llama 3.2 - answer\n",
      "I'm not sure from the notes.\n",
      "\n",
      "From general knowledge: I don't have any information about Schwarz Kaufland & Lidl.\n",
      "\n",
      " --- END OF ANSWER ---\n",
      "\n",
      "gemma 2 - answer\n",
      "I am Gemma, an AI assistant trained to be informative and comprehensive.\n",
      "\n",
      "Source: from notes\n",
      "\n",
      " --- END OF ANSWER ---\n",
      "\n",
      "phi 3.5 - answer\n",
      "I'm just a language model AI developed by Microsoft, so I don'thy have feelings. However, I'm fully operational and ready to assist you! How can I help today? (Answer sourced from general knowledge)\n",
      "\n",
      " --- END OF ANSWER ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "llama 3 - total      60\n",
       "llama 3.2 - total    17\n",
       "gemma 2 - total      56\n",
       "phi 3.5 - total      57\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2 = general.tail(1)\n",
    "\n",
    "for i in range(2, 10, 2):\n",
    "    print(general.columns[i])\n",
    "    print(q2.iloc[0, i])\n",
    "    print(\"\\n --- END OF ANSWER ---\\n\")\n",
    "\n",
    "general.iloc[:,[3,5,7,9]].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that all LLMs, except for llama3.2, \"know\" that they are an AI or LLM. However, gemma2 \"knows\" its name and phi3.5 \"knows\" its developer (Microsoft).\n",
    "\n",
    "Overall, llama3, the model with the most parameters, reaches the highest score, closely followed by gemma2 and phi3.5. llama3.2, the smallest LLM, clearly reaches last place.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Topic 2 - Decision Trees**\n",
    "\n",
    "The questions about the Decision Trees note are of the structure I described before, first general, then two follow-up questions.\n",
    "\n",
    "1. what can you tell me about decision trees, based on my notes\n",
    "2. Explain to me what \"breadth\" means in the context of Decision Trees\n",
    "3. What methods to fight overfitting are there in the context of decision trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note</th>\n",
       "      <th>question</th>\n",
       "      <th>llama3 -answer</th>\n",
       "      <th>llama 3 - total</th>\n",
       "      <th>llama 3.2 - answer</th>\n",
       "      <th>llama 3.2 - total</th>\n",
       "      <th>gemma 2 - answer</th>\n",
       "      <th>gemma 2 - total</th>\n",
       "      <th>phi 3.5 - answer</th>\n",
       "      <th>phi 3.5 - total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decision trees</td>\n",
       "      <td>what can you tell me about decision trees, bas...</td>\n",
       "      <td>Based on your notes, here's what I can summari...</td>\n",
       "      <td>29</td>\n",
       "      <td>I can provide an answer based on my general kn...</td>\n",
       "      <td>20</td>\n",
       "      <td>Based on your notes, here's a breakdown of dec...</td>\n",
       "      <td>26</td>\n",
       "      <td>Based on the provided notes from a data scienc...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision trees</td>\n",
       "      <td>Explain to me what \"breadth\" means in the cont...</td>\n",
       "      <td>According to your notes, \"Breadth\" refers to t...</td>\n",
       "      <td>27</td>\n",
       "      <td>From notes:\\n\\nIn the context of decision tree...</td>\n",
       "      <td>13</td>\n",
       "      <td>In the context of decision trees, \"breadth\" re...</td>\n",
       "      <td>30</td>\n",
       "      <td>In the provided note excerpts regarding decisi...</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decision trees</td>\n",
       "      <td>What methods to fight overfitting are there in...</td>\n",
       "      <td>What methods to fight overfitting are there in...</td>\n",
       "      <td>29</td>\n",
       "      <td>From notes:\\n\\nOverfitting is a common issue w...</td>\n",
       "      <td>-3</td>\n",
       "      <td>Here are a few methods for fighting overfittin...</td>\n",
       "      <td>30</td>\n",
       "      <td>From the provided \"Notes\" on Decision Trees wi...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             note                                           question  \\\n",
       "0  decision trees  what can you tell me about decision trees, bas...   \n",
       "1  decision trees  Explain to me what \"breadth\" means in the cont...   \n",
       "2  decision trees  What methods to fight overfitting are there in...   \n",
       "\n",
       "                                      llama3 -answer  llama 3 - total  \\\n",
       "0  Based on your notes, here's what I can summari...               29   \n",
       "1  According to your notes, \"Breadth\" refers to t...               27   \n",
       "2  What methods to fight overfitting are there in...               29   \n",
       "\n",
       "                                  llama 3.2 - answer  llama 3.2 - total  \\\n",
       "0  I can provide an answer based on my general kn...                 20   \n",
       "1  From notes:\\n\\nIn the context of decision tree...                 13   \n",
       "2  From notes:\\n\\nOverfitting is a common issue w...                 -3   \n",
       "\n",
       "                                    gemma 2 - answer  gemma 2 - total  \\\n",
       "0  Based on your notes, here's a breakdown of dec...               26   \n",
       "1  In the context of decision trees, \"breadth\" re...               30   \n",
       "2  Here are a few methods for fighting overfittin...               30   \n",
       "\n",
       "                                    phi 3.5 - answer  phi 3.5 - total  \n",
       "0  Based on the provided notes from a data scienc...               26  \n",
       "1  In the provided note excerpts regarding decisi...              -10  \n",
       "2  From the provided \"Notes\" on Decision Trees wi...               25  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrees = scores.iloc[[0,1,2,],:]\n",
    "dtrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the total scores for the Decision Trees questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama 3 - total      85\n",
       "llama 3.2 - total    30\n",
       "gemma 2 - total      86\n",
       "phi 3.5 - total      41\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrees.iloc[:,[3,5,7,9]].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, Llama3 and gemma2 reach the highest scores with twice as many points as the third place phi3.5. Llama3.2 again is clearly in last place.\n",
    "\n",
    "As an example, lets look at the second question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3 -answer\n",
      "Reached score for 2nd question: 27\n",
      "According to your notes, \"Breadth\" refers to the number of leaf nodes in a decision tree.\n",
      "\n",
      "Source: From Notes\n",
      "\n",
      " --- END OF ANSWER ---\n",
      "\n",
      "llama 3.2 - answer\n",
      "Reached score for 2nd question: 13\n",
      "From notes:\n",
      "\n",
      "In the context of decision trees, \"breadth\" refers to the number of nodes on a given level (or layer) of the tree. Specifically, it measures the depth or height of the tree.\n",
      "\n",
      "Breadth is often represented graphically by the number of leaves (or terminal nodes) on each branch, rather than the number of internal nodes (also called \"splitting decisions\" in decision trees). The more branching, the greater the breadth.\n",
      "\n",
      "In other words, if a node has many children, it's like having many different paths or branches that can be taken from the current point. This increased complexity often leads to better performance, as the tree is able to capture more relevant relationships between features and the target variable.\n",
      "\n",
      "Breadth is an important aspect of decision trees, as it affects their ability to:\n",
      "\n",
      "Capture complex interactions between features\n",
      "Handle high-dimensional data (where many features are present)\n",
      "Prevent overfitting by reducing the impact of noise in the training data\n",
      "By increasing the breadth of a decision tree, you can improve its robustness and generalizability, making it more suitable for real-world applications where data may be noisy or incomplete.\n",
      "\n",
      " --- END OF ANSWER ---\n",
      "\n",
      "gemma 2 - answer\n",
      "Reached score for 2nd question: 30\n",
      "In the context of decision trees, \"breadth\" refers to the number of leaf nodes (or outcomes) that are present on a particular level within the tree structure. It's essentially how many different classifications or predictions exist at that specific stage of the process.\n",
      "\n",
      "Here's an analogy: Imagine the decision tree as a branching forest. The breadth would tell you how many trees there are in a given area, like a patch of woods after you cut down some branches (that's analogous to pruning).\n",
      "\n",
      "Source: 'from notes\n",
      "\n",
      " --- END OF ANSWER ---\n",
      "\n",
      "phi 3.5 - answer\n",
      "Reached score for 2nd question: -10\n",
      "In the provided note excerpts regarding decision trees and video processing systems (which seem related but are not explicitly about machine learning), there isn't a direct reference or clear definition for 'breadth'. However, drawing from general knowledge within computer vision/machine learning contexts:\n",
      "\n",
      "\"Breadth,\" in common terminologies outside of the specific provided notes on decision trees and video processing systems (which relate more to robotics control than pure machine learning), typically refers not directly linked concepts. In a broad sense related to image or object detection, 'breadth' could be loosely interpreted as analogous to field-of-view in camera sensorsâ€”the extent of the area covered by an imaging system at any given moment (from general knowledge).\n",
      "\n",
      "However, since this does not precisely align with machine learning concepts like decision trees and there is no direct mention within your notes on 'breadth' as it relates to Decision Trees in a specific context such as dataset segmentation or label detection (\"needs labeling\"), I am going to interpret the term based upon its potential relation between these domains:\n",
      "\n",
      "In machine learning, \"breadth\" is not commonly used; however, if we were discussing algorithms that capture video frames for decision-making purposes (as suggested by terms like 'capturing video'), it could informally refer to how much of a scene or multiple views the algorithm takes into account simultaneously. For example:\n",
      "\n",
      "In scenarios where Decision Trees are used as part of an autonomous system, such as controlling buttons for driving in robotics (suggested by \"controlling buttons/driving\"), 'breadth' could metaphorically refer to the algorithmâ€™s capability or scopeâ€”how extensively it can analyze different inputs at one time.\n",
      "When discussing datasets, especially those relevant to video processing and autonomous systems (\"Detection\" versus \"Segmentation\", needs labeling), 'breadth' might describe how comprehensive a dataset is in capturing various scenarios or objects within its range of observationsâ€”how extensive the coverage (akin to camera field-of-view) it encompasses for effective learning and detection.\n",
      "In machine learning, where decision trees are often used alongside other algorithms such as neural networks when processing video frames (\"breadth\" could refer loosely to how many distinct dimensions or features the combined system evaluates simultaneously (e.g., color gradients, motion vectors) for labeling and object detection tasks). In this context without specific details in your notes linking 'breadth' directly with Decision Trees within machine learning itself (\"all indicators point to a need for extrapolation based on â€˜general knowledgeâ€™\"), I am providing an interpretation that draws parallels from related fields. The concept of \"breadth\" is not standardly used in the explanation or description of decision trees, as provided notes don't define it; therefore my response integrates some informed conjecture (\"from general knowledge\").\n",
      "If 'breadth' was intended to refer directly and specifically within a machine learning contextâ€”which appears absent from your given text snippets â€”it would typically mean the maximum depth or extent of data processing in branching structures, not commonly named so. Without further clarification on how it relates precisely here (or additional information), this is an informed guess using broader knowledge outside these notes (\"all indicators point to â€˜from general knowledgeâ€™\").\n",
      "\n",
      " --- END OF ANSWER ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q2 = dtrees.iloc[[1],:]\n",
    "for i in range(2, 10, 2):\n",
    "    print(dtrees.columns[i])\n",
    "    print(f\"Reached score for 2nd question: {dtrees.iloc[1, i+1]}\")\n",
    "    print(q2.iloc[0, i])\n",
    "    print(\"\\n --- END OF ANSWER ---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models answers represent the overall rating. Phi3.5 unfortunately wasnt able to answer the question at all and only produced hallucinations, therefore reaching a score of -10.\n",
    "\n",
    "---\n",
    "\n",
    "### Topic 3 - Pandas Dataframe\n",
    "\n",
    "The questions about the Pandas Dataframe note are of the structure I described before, first general, then two follow-up questions.\n",
    "\n",
    "1. what can you tell me about pandas dataframes, based on my notes\n",
    "2. How can I group a Dataframe by a column named \"name\"?\n",
    "3. How to read-in an excel file with the name \"collected-data\" into a pandas dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note</th>\n",
       "      <th>question</th>\n",
       "      <th>llama3 -answer</th>\n",
       "      <th>llama 3 - total</th>\n",
       "      <th>llama 3.2 - answer</th>\n",
       "      <th>llama 3.2 - total</th>\n",
       "      <th>gemma 2 - answer</th>\n",
       "      <th>gemma 2 - total</th>\n",
       "      <th>phi 3.5 - answer</th>\n",
       "      <th>phi 3.5 - total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pandas df</td>\n",
       "      <td>what can you tell me about pandas dataframes, ...</td>\n",
       "      <td>Based on your notes, here's what I can tell yo...</td>\n",
       "      <td>8</td>\n",
       "      <td>Based on your provided notes, here's what I ca...</td>\n",
       "      <td>14</td>\n",
       "      <td>Based on the provided notes, here's what I kno...</td>\n",
       "      <td>18</td>\n",
       "      <td>From \"notes\" provided regarding machine learni...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pandas df</td>\n",
       "      <td>How can I group a Dataframe by a column named ...</td>\n",
       "      <td>From Notes:\\n\\nTo group a DataFrame by a colum...</td>\n",
       "      <td>20</td>\n",
       "      <td>Based on your provided notes, here's what I ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>To group a DataFrame by a column named \"name\" ...</td>\n",
       "      <td>10</td>\n",
       "      <td>From Problemset 3 in your provided notes (\"all...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pandas df</td>\n",
       "      <td>How to read-in an excel file with the name \"co...</td>\n",
       "      <td>Based on the provided notes, I can see that Pa...</td>\n",
       "      <td>30</td>\n",
       "      <td>Based on your provided notes, here's what I ca...</td>\n",
       "      <td>3</td>\n",
       "      <td>To read an Excel file named \"collected-data\" i...</td>\n",
       "      <td>27</td>\n",
       "      <td>From Problemset 2 in your provided notes (\"all...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        note                                           question  \\\n",
       "3  pandas df  what can you tell me about pandas dataframes, ...   \n",
       "4  pandas df  How can I group a Dataframe by a column named ...   \n",
       "5  pandas df  How to read-in an excel file with the name \"co...   \n",
       "\n",
       "                                      llama3 -answer  llama 3 - total  \\\n",
       "3  Based on your notes, here's what I can tell yo...                8   \n",
       "4  From Notes:\\n\\nTo group a DataFrame by a colum...               20   \n",
       "5  Based on the provided notes, I can see that Pa...               30   \n",
       "\n",
       "                                  llama 3.2 - answer  llama 3.2 - total  \\\n",
       "3  Based on your provided notes, here's what I ca...                 14   \n",
       "4  Based on your provided notes, here's what I ca...                  0   \n",
       "5  Based on your provided notes, here's what I ca...                  3   \n",
       "\n",
       "                                    gemma 2 - answer  gemma 2 - total  \\\n",
       "3  Based on the provided notes, here's what I kno...               18   \n",
       "4  To group a DataFrame by a column named \"name\" ...               10   \n",
       "5  To read an Excel file named \"collected-data\" i...               27   \n",
       "\n",
       "                                    phi 3.5 - answer  phi 3.5 - total  \n",
       "3  From \"notes\" provided regarding machine learni...                6  \n",
       "4  From Problemset 3 in your provided notes (\"all...               13  \n",
       "5  From Problemset 2 in your provided notes (\"all...               11  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df = scores.iloc[[3,4,5,],:]\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama 3 - total      58\n",
       "llama 3.2 - total    17\n",
       "gemma 2 - total      55\n",
       "phi 3.5 - total      30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df.iloc[:,[3,5,7,9]].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also for the second topic, Llama3 and gemma2 are the clear winners with small differences, phi3.5 comes in third place and llama3.2 at the bottom. For this topic, I want to take a closer look at the answers of the llama3.2 model, to show reasons for the bad score.\n",
    "\n",
    "First I will present the first question and answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached score: 14\n",
      "Based on your provided notes, here's what I can infer about Pandas DataFrames:\n",
      "\n",
      "You have mentioned handling NumPy arrays.\n",
      "You have also talked about handling Pandas DataFrames.\n",
      "Pandas DataFrames are a fundamental data structure in Python for data manipulation and analysis. They are similar to Excel tables or SQL tables but offer more features and functionality.\n",
      "\n",
      "Here's a summary of what you can tell me about Pandas DataFrames based on your notes:\n",
      "\n",
      "You have discussed how to handle Pandas DataFrames using NumPy arrays.\n",
      "You haven't explicitly mentioned any specific methods or functions for handling DataFrames, but it seems that you're familiar with the basic concepts and operations.\n",
      "If I had to extract more information from your notes, I would say that you've covered some of the essential topics related to Pandas DataFrames, such as:\n",
      "\n",
      "Reading Data using Pandas\n",
      "Creating DataFrames using data sources (e.g., NumPy arrays)\n",
      "Filtering, grouping, aggregating, and plotting DataFrames\n",
      "Using Seaborn for visualizing data\n",
      "Renaming columns in DataFrames\n",
      "However, there's no specific information about advanced topics like melting, merge, or using Pandas to make API requests. If you're working with these features, I recommend checking out the official Pandas documentation or other resources that provide more detailed information.\n",
      "\n",
      "Sources:\n",
      "\n",
      "from notes\n"
     ]
    }
   ],
   "source": [
    "print(f\"Reached score: {pandas_df.iloc[0,5]}\")\n",
    "print(pandas_df.iloc[0,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the answer reached a score of 14. In general, the LLM and RAG-workflow correctly identified the topic. However, the RAG-Worklfow did not retrieve the note about Pandas Dataframes (which is included in this repo), but another note mentioning the Dataframes. Therefore, a lot of information, which can be found in the notes, is left out and not mentioned, leading to a bad score for completeness and way of using provided information.\n",
    "\n",
    "Now lets take a look at the last question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached score: 3\n",
      "Based on your provided notes, here's what I can infer about reading in an Excel file:\n",
      "\n",
      "You have discussed handling NumPy arrays.\n",
      "You have also talked about handling Pandas DataFrames.\n",
      "To read in an Excel file using the name \"collected-data\", you can use the read_excel function from pandas. Here's how it works:\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "# Read in the Excel file 'collected-data.xlsx'\n",
      "df = pd.read_excel('collected-data.xlsx')\n",
      "\n",
      "# Print the result\n",
      "print(df)\n",
      "\n",
      "This will output:\n",
      "\n",
      "name  age city\n",
      "0    John   28  New York\n",
      "1     Anna   24    Paris\n",
      "2      Peter   35  Berlin\n",
      "3       Linda   32    London\n",
      "\n",
      "The read_excel function takes the file path as an argument and returns a pandas DataFrame.\n",
      "\n",
      "When to use reading in Excel files:\n",
      "\n",
      "When you want to work with data that is stored in an Excel file\n",
      "To load large datasets into memory (more efficient than reading files sequentially)\n",
      "To perform data manipulation, filtering, or grouping operations on the data\n",
      "Note: You can also specify additional arguments to customize the read process, such as:\n",
      "\n",
      "sheet_name: Specify the name of the sheet containing the data.\n",
      "na_values: Specify a list of values that should be treated as missing (NaN) during reading.\n",
      "Sources:\n",
      "\n",
      "from notes\n"
     ]
    }
   ],
   "source": [
    "print(f\"Reached score: {pandas_df.iloc[2,5]}\")\n",
    "print(pandas_df.iloc[2,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the RAG-Workflow retrieved a different note than intended. While the provided information is correct, it mentions a few unneccesary things and doesnt use some of the information provided in the actual PD Dataframe note.\n",
    "\n",
    "To conclude, the RAG-Workflow and correct retrieval of relevant information is very important to the scoring and the correct respond heavily depends on it.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Topic 4 - VADER Sentiment Analysis**\n",
    "\n",
    "The questions about the Pandas Dataframe note are of the structure I described before, first general, then two follow-up questions.\n",
    "\n",
    "1. what can you tell me about vader sentiment analysis, based on my notes\n",
    "2. what does the term \"lexicon\" mean in connection to VADER sentiment analysis?\n",
    "3. can you find  a simple code implementation for vader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note</th>\n",
       "      <th>question</th>\n",
       "      <th>llama3 -answer</th>\n",
       "      <th>llama 3 - total</th>\n",
       "      <th>llama 3.2 - answer</th>\n",
       "      <th>llama 3.2 - total</th>\n",
       "      <th>gemma 2 - answer</th>\n",
       "      <th>gemma 2 - total</th>\n",
       "      <th>phi 3.5 - answer</th>\n",
       "      <th>phi 3.5 - total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vader</td>\n",
       "      <td>what can you tell me about vader sentiment ana...</td>\n",
       "      <td>Based on the provided notes, there is no menti...</td>\n",
       "      <td>0</td>\n",
       "      <td>Based on your provided notes, here's what I ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>VADER (Valence Aware Dictionary for sEntiment ...</td>\n",
       "      <td>30</td>\n",
       "      <td>From \"general knowledge,\" VADER (Valence Aware...</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vader</td>\n",
       "      <td>what does the term \"lexicon\" mean in connectio...</td>\n",
       "      <td>Based on the provided notes, I can see that wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>what does the term \"lexicon\" mean in connectio...</td>\n",
       "      <td>7</td>\n",
       "      <td>In the context of VADER sentiment analysis, a ...</td>\n",
       "      <td>30</td>\n",
       "      <td>In relation to VADER (Valence Aware Dictionary...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vader</td>\n",
       "      <td>can you find  a simple code implementation for...</td>\n",
       "      <td>Yes, I can find a simple code implementation f...</td>\n",
       "      <td>30</td>\n",
       "      <td>from nltk.sentiment.vader import SentimentInte...</td>\n",
       "      <td>30</td>\n",
       "      <td>Yes, the provided code snippet demonstrates a ...</td>\n",
       "      <td>20</td>\n",
       "      <td>Yes, I can outline a simplified Python code ex...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    note                                           question  \\\n",
       "6  vader  what can you tell me about vader sentiment ana...   \n",
       "7  vader  what does the term \"lexicon\" mean in connectio...   \n",
       "8  vader  can you find  a simple code implementation for...   \n",
       "\n",
       "                                      llama3 -answer  llama 3 - total  \\\n",
       "6  Based on the provided notes, there is no menti...                0   \n",
       "7  Based on the provided notes, I can see that wo...                0   \n",
       "8  Yes, I can find a simple code implementation f...               30   \n",
       "\n",
       "                                  llama 3.2 - answer  llama 3.2 - total  \\\n",
       "6  Based on your provided notes, here's what I ca...                  0   \n",
       "7  what does the term \"lexicon\" mean in connectio...                  7   \n",
       "8  from nltk.sentiment.vader import SentimentInte...                 30   \n",
       "\n",
       "                                    gemma 2 - answer  gemma 2 - total  \\\n",
       "6  VADER (Valence Aware Dictionary for sEntiment ...               30   \n",
       "7  In the context of VADER sentiment analysis, a ...               30   \n",
       "8  Yes, the provided code snippet demonstrates a ...               20   \n",
       "\n",
       "                                    phi 3.5 - answer  phi 3.5 - total  \n",
       "6  From \"general knowledge,\" VADER (Valence Aware...               -8  \n",
       "7  In relation to VADER (Valence Aware Dictionary...               28  \n",
       "8  Yes, I can outline a simplified Python code ex...               -3  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader = scores.iloc[[6,7,8],:]\n",
    "vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama 3 - total      30\n",
       "llama 3.2 - total    37\n",
       "gemma 2 - total      80\n",
       "phi 3.5 - total      17\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader.iloc[:,[3,5,7,9]].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, in this topic LLama3 does not reach first place and only lands in third place. Gemma2 however reaches a similar high score as before. Phi3.5 and Llama3.2 still build the bottom of the leaderboard, but have switched places, now with phi3.5 in last place.\n",
    "\n",
    "Finally, lets take a look at the two answers of Llama3, which resulted in such a low scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached score: 0\n",
      "Based on the provided notes, there is no mention of \"Vader Sentiment Analysis\". Therefore, I will provide an answer based on my own knowledge.\n",
      "\n",
      "Vader Sentiment Analysis is a tool used to analyze the sentiment (positive or negative) of text data. It was developed by Stanford Natural Language Processing Group and is widely used in natural language processing and text analysis applications.\n",
      "\n",
      "It's not specifically mentioned in your notes, but it seems that you are studying Data Science, which includes tasks such as data cleaning, annotation, training models, and visualization. Vader Sentiment Analysis can be a useful tool for analyzing the sentiment of text data, which is a common task in many data science projects.\n",
      "\n",
      "Source: from general knowledge\n"
     ]
    }
   ],
   "source": [
    "print(f\"Reached score: {vader.iloc[0,3]}\")\n",
    "print(vader.iloc[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached score: 0\n",
      "Based on the provided notes, I can see that word embeddings are discussed, but there's no mention of VADER sentiment analysis specifically. However, since you're asking about a term related to sentiment analysis, I'll provide an answer.\n",
      "\n",
      "In the context of natural language processing and sentiment analysis, \"lexicon\" refers to a collection of words with their corresponding meanings or nuances. In other words, it's a dictionary-like resource that provides information on word semantics, connotations, and relationships.\n",
      "\n",
      "In VADER (Valence Aware Dictionary and sEntiment Reasoner) sentiment analysis specifically, the lexicon is likely used to capture the emotional tone of words, phrases, and sentences. The lexicon would contain pre-defined rules for identifying the sentiment (positive, negative, or neutral) of each word or phrase, allowing VADER to analyze text data and determine its overall sentiment.\n",
      "\n",
      "Source: from general knowledge\n"
     ]
    }
   ],
   "source": [
    "print(f\"Reached score: {vader.iloc[1,3]}\")\n",
    "print(vader.iloc[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both questions, the RAG-Worklflow failed and did not provide the correct information. Therefore, the LLM fell back to its own knowledge instead of using the provided notes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Overall winner**\n",
    "\n",
    "To conclude the scoring, I will aggregate the sum of each models topic-scores and present the overall leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama 3 - total      233\n",
       "llama 3.2 - total    101\n",
       "gemma 2 - total      277\n",
       "phi 3.5 - total      145\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general.iloc[:,[3,5,7,9]].sum() + dtrees.iloc[:,[3,5,7,9]].sum() + pandas_df.iloc[:,[3,5,7,9]].sum() + vader.iloc[:,[3,5,7,9]].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The leaderboard shows **Gemma2 with 3B parameters as the winner**, followed by LLama3 8B in second place, Phi3.5 3.8B with quite a distance in third place and lastly Llama3.2 1B.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **II. Observations**\n",
    "\n",
    "**IMPORTANT:** The following observations are **heavily biased** and were written based on my (the testers) experience and opinion when using the models.\n",
    "\n",
    "**Llama3**\n",
    "- sticks close to provided content from notes\n",
    "- always provides source in the same \"manner\"\n",
    "\n",
    "**Llama3.2 1B**\n",
    "- \"strays\" from provided content --> it mixes provided and own knowledge, not clearly marking when it does it. While this can be useful, its not clear how much the provided knowledge is used at all\n",
    "- very often uses noticebly own knowledge and still states it as \"Source: your notes\"\n",
    "- sometimes mixes up topics or uses completely irrelevant information\n",
    "\n",
    "**Gemma2 2B**\n",
    "- uses emojis --> positive experience\n",
    "- general tone and \"way of talking\" sounds better than Llama3.2 1B and Llama3\n",
    "\t- Uses rhetorical methods: (What are they?Â Pandas DataFrames are essentially tables of data. Think of them like spreadsheets or databases with rows and columns that organize your information neatly. Why are they useful?Â They provide a powerful way to store and manipulate structured data in Python, making it much easier than handling raw arrays.)\n",
    "- often uses provided notes and adds own knowledge to further explain\n",
    "\t- but also keeps answers short if question is clear and only requires short, precise answer\n",
    "\t- anyway always states the source would be from notes\n",
    "\n",
    "**Phi 3.5**\n",
    "- hallucinates non-existent words sometimes (e.g.: DonÂ´thy)\n",
    "- often uses provided notes and adds own knowledge to further explain, but anyway states the source would be from notes\n",
    "- in comparison to gemma2, writes lengthy answers\n",
    "- has a \"weird\" style, uses brackets a lot, mentions source in an unclear way (\"all indicators point back here\")\n",
    "- understands Obsidian \"tags\" (mentioned it and understood its context)\n",
    "- sometimes mentions exact note used as source, which is good\n",
    "- sometimes only produces hallucination: invents words, writes japanese or other non-latin letters and complete \"nonsense\", meaning sentences with no meaning or structure.\n",
    "\n",
    "---\n",
    "\n",
    "## **III. Conclusion / Personal Opinion**\n",
    "\n",
    "\n",
    "First of all, it is important to mention that the RAG-Workflow \"failed\" multiple times, as shown above and provided unmatching content to the LLMs, although the embedding model and the content or the questions werent changed throughout the testing. Therefore the testing environment wasnt the same to a hundred percent in each case, even if no changes to the code or system were made. However, I intend this project to be useful for the end-user (myself) and therefore want to evaluate the experience the user has when using the system. \"Pressing out\" the last possible points a model can reach is not serving the purpose of this project, but evaluating first-try experience is.\n",
    "\n",
    "The prompt used is another crucial part of the RAG-workflow, along with the correct retrieval of embeddings. As explained in the Introduction, I wanted the LLM to fulfill two major guidelines: first, to stick to my notes and only fall back to its own knowledge if necessary and second, to always provide a source. While all models fulfilled the second task in every response, it was often untrue. As listed in the observations, some models, like Gemma2, often mixed the knowledge from my notes and their own knowledge, but still stated the source to be my notes. This is rather unsatisfying. Furthermore, a clear line between own and provided knowledge cant be drawn. Therefore the models cant be evaluated in a comprehensive way for this matter. This is also the case for the first guideline. It is difficult to determine, wether it was necessary or not, in cases where the model mixed-in its own knowledge. For the prompt, I can simply conclude that all models always provide a source, wether it is true or not and the first guideline is very \"flexible\", making an evaluation very difficult. Further prompt-engineering could lead to the models sticking closer to the rules, but also effect the user-experience.\n",
    "\n",
    "To sum it up, based on the provided scoring and the observations, **my personal favorite and the overall best experience I had with Gemma2 2B.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Final Remark**\n",
    "\n",
    "It is important to keep in mind that the tested models have different amounts of parameters and use different amounts of memory, because they were made for different purposes. A Llama3 with 8B will always overall perform better than a Llama3.2 with only 1B. Therefore, the hardware one intends to use the LLM on has to be taken into consideration when using the testing and scoring as means to evaluate which model to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sources**\n",
    "\n",
    "Obsidian: https://obsidian.md\n",
    "\n",
    "Streamlit: https://streamlit.io\n",
    "\n",
    "Ollama: https://ollama.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
